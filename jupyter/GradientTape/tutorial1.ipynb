{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c704d31a",
   "metadata": {},
   "source": [
    "[Median Source](https://medium.com/analytics-vidhya/tf-gradienttape-explained-for-keras-users-cc3f06276f22)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b4608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "When x is a constant we need to use watch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5d6fa",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee3a8ad",
   "metadata": {},
   "source": [
    "## when variable is a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeaffe22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:30:47.001266Z",
     "start_time": "2023-03-02T14:30:46.998538Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(5.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    # need to watch\n",
    "    tape.watch(x)\n",
    "    y = x**3\n",
    "\n",
    "# typically the gd is an eager tensor and you can call numpy() to see the value\n",
    "gd = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1816bf8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:30:47.688520Z",
     "start_time": "2023-03-02T14:30:47.684460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=75.0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5df54",
   "metadata": {},
   "source": [
    "## when variable is trainable instead of constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9ecec5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:31:06.333828Z",
     "start_time": "2023-03-02T14:31:06.330392Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(6.0, trainable=True)\n",
    "with tf.GradientTape() as tape:\n",
    "    # no need to watch\n",
    "    y = x**3\n",
    "\n",
    "# typically the gd is an eager tensor and you can call numpy() to see the value\n",
    "gd = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2931de0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:35:44.220471Z",
     "start_time": "2023-03-02T14:35:44.217311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=108.0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdb516",
   "metadata": {},
   "source": [
    "# Higher Order deravative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d345c034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:32:59.764834Z",
     "start_time": "2023-03-02T14:32:59.758368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "27.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0, trainable=True)\n",
    "with tf.GradientTape() as tape1:\n",
    "    with tf.GradientTape() as tape2:\n",
    "        y = x ** 3\n",
    "    order_1 = tape2.gradient(y, x)\n",
    "order_2 = tape1.gradient(order_1, x)\n",
    "\n",
    "print(order_2.numpy()) # -> 18.0\n",
    "print(order_1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb11ec7",
   "metadata": {},
   "source": [
    "# Persistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3493e9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:37:47.318632Z",
     "start_time": "2023-03-02T14:37:47.313772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = tf.Variable(6.0, trainable=True)\n",
    "b = tf.Variable(2.0, trainable=True)\n",
    "# without persistent = True, calling tape.gradient will through exceptions when you call it the second time\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y1 = a ** 2\n",
    "    y2 = b ** 3\n",
    "                                                                                                                                                                                                                                                                                                                                                \n",
    "print(tape.gradient(y1, a).numpy())\n",
    "print(tape.gradient(y2, b).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f845be8",
   "metadata": {},
   "source": [
    "# Real example on Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18780ea6",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "010c9481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:52:04.563111Z",
     "start_time": "2023-03-02T14:52:04.559198Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Loss function\n",
    "def loss(real_y, pred_y):\n",
    "    return tf.abs(real_y - pred_y)\n",
    "\n",
    "# Training data\n",
    "x_train = np.asarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_train = np.asarray([i*10+5 for i in x_train]) # y = 10x+5\n",
    "\n",
    "# Trainable variables\n",
    "a = tf.Variable(random.random(), trainable=True)\n",
    "b = tf.Variable(random.random(), trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474b734",
   "metadata": {},
   "source": [
    "## step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a91d691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:52:05.128093Z",
     "start_time": "2023-03-02T14:52:05.125324Z"
    }
   },
   "outputs": [],
   "source": [
    "def step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Make prediction\n",
    "        pred_y = a * real_x + b\n",
    "        # Calculate loss\n",
    "        reg_loss = loss(real_y, pred_y)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    a_gradients, b_gradients = tape.gradient(reg_loss, (a, b))\n",
    "\n",
    "    # Update variables\n",
    "    a.assign_sub(a_gradients * 0.01)\n",
    "    b.assign_sub(b_gradients * 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6162f34c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T14:52:07.679535Z",
     "start_time": "2023-03-02T14:52:05.908599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ 9.973946571350098x + 4.98994779586792\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2000):\n",
    "    step(x_train, y_train)\n",
    "\n",
    "print(f'y ≈ {a.numpy()}x + {b.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f2634",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "944b8ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T15:11:09.771169Z",
     "start_time": "2023-03-02T15:11:06.170659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y ≈ 6.427342414855957x^2 + 7.563826560974121x + 2.010007619857788\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "def loss(real_y, pred_y):\n",
    "    return tf.abs(real_y - pred_y)\n",
    "\n",
    "# Training data\n",
    "x_train = np.asarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_train = np.asarray([6*i**2 + 8*i + 2 for i in x_train]) # y = 6x^2 + 8x + 2\n",
    "\n",
    "# Trainable variables\n",
    "a = tf.Variable(random.random(), trainable=True)\n",
    "b = tf.Variable(random.random(), trainable=True)\n",
    "c = tf.Variable(random.random(), trainable=True)\n",
    "lr = 0.001\n",
    "\n",
    "# Step function\n",
    "def step(x_real, y_real):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        y_pred = a * x_real**2 + b * x_real + c\n",
    "        closs = loss(y_real, y_pred)\n",
    "    ga,gb,gc = tape.gradient(closs, (a,b,c))\n",
    "    a.assign_sub(ga*lr)\n",
    "    b.assign_sub(gb*lr)\n",
    "    c.assign_sub(gc*lr)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for _ in range(3000):\n",
    "    step(x_train, y_train)\n",
    "\n",
    "print(f'y ≈ {a.numpy()}x^2 + {b.numpy()}x + {c.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e74fe",
   "metadata": {},
   "source": [
    "# Real example in nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae8da9",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad93adf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T15:38:02.386390Z",
     "start_time": "2023-03-02T15:38:02.167284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal \n",
    "\n",
    "# Load and pre-process training data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = (x_train / 255).reshape((-1, 28, 28, 1))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "x_test = (x_test / 255).reshape((-1, 28, 28, 1))\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "optimizer = Adam(lr=0.001)\n",
    "weight_init = RandomNormal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5771e8",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b55f6ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T15:39:50.194053Z",
     "start_time": "2023-03-02T15:39:50.113791Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/anaconda3/envs/tf_211/lib/python3.10/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer=weight_init, input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer=weight_init))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer=weight_init))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer=weight_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4df16",
   "metadata": {},
   "source": [
    "## define step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e7690d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T15:42:11.407186Z",
     "start_time": "2023-03-02T15:42:11.403298Z"
    }
   },
   "outputs": [],
   "source": [
    "def step(real_x, real_y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make prediction\n",
    "        pred_y = model(real_x.reshape((-1, 28, 28, 1)))\n",
    "        # Calculate loss\n",
    "        model_loss = tf.keras.losses.categorical_crossentropy(real_y, pred_y)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    model_gradients = tape.gradient(model_loss, model.trainable_variables)\n",
    "    # Update model\n",
    "    optimizer.apply_gradients(zip(model_gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5570f",
   "metadata": {},
   "source": [
    "## define training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a3364928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T15:45:39.827709Z",
     "start_time": "2023-03-02T15:44:31.435780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      " 0.9860000014305115\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# Training loop\n",
    "bat_per_epoch = math.floor(len(x_train) / batch_size)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print('=', end='')\n",
    "    for i in range(bat_per_epoch):\n",
    "        n = i*batch_size\n",
    "        step(x_train[n:n+batch_size], y_train[n:n+batch_size])\n",
    "\n",
    "# Calculate accuracy\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.categorical_crossentropy, metrics=['acc']) # Compile just for evaluation\n",
    "print('\\n', model.evaluate(x_test, y_test, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c97010",
   "metadata": {},
   "source": [
    "# What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396eb0f8",
   "metadata": {},
   "source": [
    "[advanced style transfer](https://www.tensorflow.org/tutorials/generative/style_transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc651c",
   "metadata": {},
   "source": [
    "[adversarial attacks](https://medium.com/analytics-vidhya/implementing-adversarial-attacks-and-defenses-in-keras-tensorflow-2-0-cab6120c5715)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63248309",
   "metadata": {},
   "source": [
    "[transform the world with cycleGAN](https://medium.com/analytics-vidhya/transforming-the-world-into-paintings-with-cyclegan-6748c0b85632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be7209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf211",
   "language": "python",
   "name": "tf211"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
