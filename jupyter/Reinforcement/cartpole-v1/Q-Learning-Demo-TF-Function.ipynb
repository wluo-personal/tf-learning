{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1655d2b7",
   "metadata": {},
   "source": [
    "This notebook focus on Actor-Critc and A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cf64ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.536526Z",
     "start_time": "2023-03-23T15:54:58.510540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 15:54:58.617214: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 15:54:58.699087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:58.699103: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-23 15:54:59.083418: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.083457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.083461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# disable tensorflow logging\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import tqdm\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec5b7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.541577Z",
     "start_time": "2023-03-23T15:54:59.538077Z"
    }
   },
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self, max_step=1000):\n",
    "        self.env = gym.make(\"CartPole-v1\")\n",
    "        self.max_step = max_step\n",
    "        self.cur_step = 1\n",
    "        self.action_space = self.env.action_space\n",
    "        \n",
    "    def reset(self):\n",
    "        self.cur_step = 1\n",
    "        initial_state, info = self.env.reset()\n",
    "        initial_state = self.add_step_into_state(initial_state)\n",
    "        return initial_state, info\n",
    "    \n",
    "    def add_step_into_state(self, state):\n",
    "#         state = np.concatenate([state, np.array([self.cur_step/self.max_step])])\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.cur_step += 1\n",
    "        state, reward, done, _, _ = self.env.step(action)\n",
    "        if self.cur_step > self.max_step:\n",
    "            reward = 1.0\n",
    "            done = True\n",
    "            self.cur_step = self.max_step + 1\n",
    "        else:\n",
    "            if done:\n",
    "                reward = 1.0\n",
    "        state = self.add_step_into_state(state)\n",
    "        return state, reward, done, _, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293f6b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.591727Z",
     "start_time": "2023-03-23T15:54:59.542496Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "# env = Env()\n",
    "initial_state, _ = env.reset()\n",
    "initial_state_shape = initial_state.shape\n",
    "action_space = env.action_space.n\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "gamma = 0.99\n",
    "lr = 0.001\n",
    "step_length = 50\n",
    "use_dueling = False \n",
    "\"\"\"Q learning training is much harder than policy gradient\"\"\"\n",
    "\n",
    "if use_dueling:\n",
    "    lr = 0.0003\n",
    "    gamma = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a500b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T15:45:52.459819Z",
     "start_time": "2023-03-15T15:45:52.453876Z"
    }
   },
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1719071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.701503Z",
     "start_time": "2023-03-23T15:54:59.592598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,898\n",
      "Trainable params: 8,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 15:54:59.657521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-23 15:54:59.657717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657753: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657828: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-23 15:54:59.657906: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-23 15:54:59.658168: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The model will use basic Q-learning\n",
    "\"\"\"\n",
    "\n",
    "def get_model():\n",
    "    inputs = tf.keras.layers.Input(shape=initial_state_shape)\n",
    "    hidden = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "    hidden = tf.keras.layers.Dense(128, activation=\"relu\")(hidden)\n",
    "    outs = tf.keras.layers.Dense(action_space, activation=None)(hidden)\n",
    "    return tf.keras.Model(inputs, outs)\n",
    "\n",
    "def get_dueling_model():\n",
    "    \"\"\"\n",
    "    A = Q - S\n",
    "    Q = A + S - mean(A)\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=initial_state_shape)\n",
    "    hidden = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "    hidden = tf.keras.layers.Dense(128, activation=\"relu\")(hidden)\n",
    "    A = tf.keras.layers.Dense(action_space, activation=None)(hidden)\n",
    "    S = tf.keras.layers.Dense(1, activation=None)(hidden)\n",
    "    A_mean = tf.math.reduce_mean(A, axis=1, name=\"mean\")\n",
    "    outs = tf.keras.layers.Add(name=\"outs\")([A, S, -A_mean])\n",
    "    \n",
    "    return tf.keras.Model(inputs, outs)\n",
    "    \n",
    "if use_dueling:\n",
    "    model = get_dueling_model()\n",
    "else:\n",
    "    model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045086a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T15:51:42.446877Z",
     "start_time": "2023-03-15T15:51:42.443577Z"
    }
   },
   "source": [
    "# define data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d600bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.708160Z",
     "start_time": "2023-03-23T15:54:59.703283Z"
    }
   },
   "outputs": [],
   "source": [
    "def _run_step_numpy(action):\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    return (state.astype(np.float32), np.array(reward, dtype=np.float32), np.array(done, dtype=np.int32))\n",
    "\n",
    "def run_step_tf(action):\n",
    "    return tf.numpy_function(_run_step_numpy, [action], (tf.float32, tf.float32, tf.int32))\n",
    "\n",
    "def run_step(start_state, model, step_length):\n",
    "\n",
    "    values = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    actions = tf.TensorArray(tf.int32, size=0, dynamic_size=True)\n",
    "    rewards = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    done = tf.constant(True, dtype=tf.bool)\n",
    "    done_shape = done.shape\n",
    "    \n",
    "    state = start_state\n",
    "    for t in tf.range(step_length):\n",
    "        q_output = model(tf.expand_dims(state, 0))\n",
    "        q_output = tf.squeeze(q_output)\n",
    "        action = tf.math.argmax(q_output, output_type=tf.int32)\n",
    "        \n",
    "        value = q_output[action]\n",
    "        state, reward, done = run_step_tf(action)\n",
    "        state.set_shape(initial_state_shape)\n",
    "        \n",
    "        actions = actions.write(t, action)\n",
    "        values = values.write(t, tf.squeeze(value))\n",
    "        rewards = rewards.write(t, reward)\n",
    "        done = tf.cast(done, dtype=tf.bool)\n",
    "        done.set_shape(done_shape)\n",
    "        if done:\n",
    "            break\n",
    "    next_value = tf.constant(0.0, dtype=tf.float32)\n",
    "    if t == step_length - 1:\n",
    "        vcomplete = 1 / (1 - gamma)\n",
    "        vcomplete = tf.constant(vcomplete, dtype=tf.float32)\n",
    "        rewards = rewards.write(t-1, vcomplete)\n",
    "     \n",
    "    actions = actions.stack()\n",
    "    values = values.stack()\n",
    "    rewards = rewards.stack()\n",
    "    return values, actions, rewards, next_value, state, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0765783e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.801683Z",
     "start_time": "2023-03-23T15:54:59.709030Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/anaconda3/envs/tf_211/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "state_, _ = env.reset()\n",
    "result = run_step(state_, model, 100)\n",
    "values, actions, rewards, next_state, state, done = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a96751",
   "metadata": {},
   "source": [
    "# define returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9412eb79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.806061Z",
     "start_time": "2023-03-23T15:54:59.802735Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_returns(rewards_array, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Input: total_rewards is a value\n",
    "    Output: \n",
    "        discount_array: array of discount rate.\n",
    "            index i to the (end timestamp + 1) discount rate\n",
    "        returns: array of discounted returns\n",
    "            index i means the returns between index i to the index(end timestamp + 1)\n",
    "    \"\"\"\n",
    "    rewards_array = tf.squeeze(rewards_array)\n",
    "    gamma = tf.constant(gamma, tf.float32)\n",
    "    discounted_return = tf.constant(0.0, tf.float32)\n",
    "    dshape = discounted_return.shape\n",
    "    returns = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    for idx in tf.range(tf.shape(rewards_array)[0] -1, -1, -1):\n",
    "        discounted_return = gamma * discounted_return + rewards_array[idx]\n",
    "        discounted_return.set_shape(dshape)\n",
    "        returns = returns.write(idx, discounted_return)\n",
    "    discount_array = tf.ones_like(rewards_array, dtype=tf.float32) * gamma\n",
    "    discount_array = tf.math.cumprod(discount_array, reverse=True)\n",
    "    returns = returns.stack()\n",
    "    \n",
    "    returns = (returns - tf.math.reduce_mean(returns)) / (eps + tf.math.reduce_std(returns))\n",
    "    \n",
    "    return discount_array, returns\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232c4638",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.824986Z",
     "start_time": "2023-03-23T15:54:59.806930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(23,), dtype=float32, numpy=\n",
       " array([0.79361445, 0.80163074, 0.809728  , 0.8179071 , 0.8261688 ,\n",
       "        0.8345139 , 0.8429433 , 0.8514579 , 0.8600585 , 0.8687459 ,\n",
       "        0.8775211 , 0.88638496, 0.89533836, 0.90438217, 0.91351736,\n",
       "        0.9227448 , 0.9320654 , 0.9414802 , 0.95099014, 0.9605961 ,\n",
       "        0.97029907, 0.98010004, 0.99      ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(23,), dtype=float32, numpy=\n",
       " array([ 1.6004506 ,  1.4650329 ,  1.3282472 ,  1.1900798 ,  1.050517  ,\n",
       "         0.90954405,  0.7671474 ,  0.6233125 ,  0.47802448,  0.33126906,\n",
       "         0.18303116,  0.03329597, -0.11795165, -0.27072698, -0.42504552,\n",
       "        -0.58092284, -0.7383747 , -0.897417  , -1.0580659 , -1.2203374 ,\n",
       "        -1.3842481 , -1.5498143 , -1.7170529 ], dtype=float32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = result[2]\n",
    "get_returns(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a873d05",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e88c5219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.828400Z",
     "start_time": "2023-03-23T15:54:59.825967Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "def calculate_loss(returns, values, value_next, discount_array):\n",
    "    \"\"\"\n",
    "    Policy part ---------\n",
    "    V(St) = E(Q) = Pi(St, At1; theta) * Q(St, At1) + ...\n",
    "    G denote gradient W.R.T theta\n",
    "    \n",
    "    \n",
    "    G(V(St)) = G[Pi(St, At1; theta) * Q(St, At1) + ...]\n",
    "                approximate= Pi(St, A1)* G(logpi(St, At1; theta) * Q) + ...  # chain rule G(logpi) = 1/pi * G(pi)\n",
    "                = E[ G(logpi * Q) ] # Pi(St, A) is the PDF, so this is the expectation\n",
    "              [1]  approximate= G(logpi * Q)  # monte carlo approximation\n",
    "              [2]  = G(logpi * (Q - baseline))  where baseline can be V. This is the A2C\n",
    "                  Qt can be approximate by Yt\n",
    "              Yt = gamma^T * Q(T) + r + gamma*r + gamma^2*r + ...\n",
    "              \n",
    "    Critic Part TD learning -----------\n",
    "    Qt = discounted_ovserved + QT\n",
    "            \n",
    "    \"\"\"\n",
    "    values = tf.squeeze(values)\n",
    "    returns = tf.squeeze(returns)\n",
    "    \n",
    "    loss = loss_func(tf.expand_dims(values, 1), tf.expand_dims(returns,1))\n",
    "    \n",
    "    return loss#, abs(Yt - values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b72202c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.843375Z",
     "start_time": "2023-03-23T15:54:59.829306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=20.00364>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, actions, rewards, next_value, state, done = result\n",
    "discount_array, returns_array = get_returns(rewards, gamma)\n",
    "calculate_loss(returns_array, values, next_value, discount_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a2689",
   "metadata": {},
   "source": [
    "# train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea4f1820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:54:59.848540Z",
     "start_time": "2023-03-23T15:54:59.844320Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "@tf.function\n",
    "def run_train_step(model, optimizer, start_state, step_length):\n",
    "    with tf.GradientTape() as tape:\n",
    "        STEP_RES = run_step(start_state, model, step_length)\n",
    "        values, actions, rewards, next_value, state, done = STEP_RES\n",
    "        discount_array, returns_array = get_returns(rewards, gamma)\n",
    "        loss = calculate_loss(returns_array, values, next_value, discount_array)\n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "    return STEP_RES, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ecf721e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:01.307797Z",
     "start_time": "2023-03-23T15:54:59.849436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
       "  array([ 0.00847541, -0.02667668,  0.00580538, -0.02851547,  0.00177115,\n",
       "         -0.0305927 , -0.06151223, -0.09285256, -0.12473955, -0.15730904,\n",
       "         -0.19074258, -0.22514847], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(12,), dtype=int32, numpy=array([1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
       "  <tf.Tensor: shape=(12,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       "  <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.07948017,  1.5441382 , -0.21186265, -2.5351312 ], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(), dtype=bool, numpy=True>),\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.400293>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_state, _ = env.reset()\n",
    "run_train_step(model, optimizer, _state, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4a1c9",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3289955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:16.480241Z",
     "start_time": "2023-03-23T15:55:01.309167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 342/10000 [00:14<06:47, 23.72it/s, current_reward=38, loss=28.8, running_rewards=68.6] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m cur_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m step_length\n\u001B[1;32m     17\u001B[0m values, actions, rewards, next_value, state, done \u001B[38;5;241m=\u001B[39m STEP_RES\n\u001B[0;32m---> 18\u001B[0m epoch_reward \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mrewards\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7327\u001B[0m, in \u001B[0;36m_TensorIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   7325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_limit:\n\u001B[1;32m   7326\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[0;32m-> 7327\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tensor\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m   7328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   7329\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1071\u001B[0m, in \u001B[0;36m_slice_helper\u001B[0;34m(tensor, slice_spec, var)\u001B[0m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(\n\u001B[1;32m   1067\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1068\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrided_slice\u001B[39m\u001B[38;5;124m\"\u001B[39m, [tensor] \u001B[38;5;241m+\u001B[39m begin \u001B[38;5;241m+\u001B[39m end \u001B[38;5;241m+\u001B[39m strides,\n\u001B[1;32m   1069\u001B[0m     skip_on_eager\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m name:\n\u001B[1;32m   1070\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m begin:\n\u001B[0;32m-> 1071\u001B[0m     packed_begin, packed_end, packed_strides \u001B[38;5;241m=\u001B[39m (stack(begin), \u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mend\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1072\u001B[0m                                                 stack(strides))\n\u001B[1;32m   1073\u001B[0m     \u001B[38;5;66;03m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001B[39;00m\n\u001B[1;32m   1074\u001B[0m     \u001B[38;5;66;03m# same dtypes.\u001B[39;00m\n\u001B[1;32m   1075\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (packed_begin\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mint64 \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1076\u001B[0m         packed_end\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mint64 \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1077\u001B[0m         packed_strides\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mint64):\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1466\u001B[0m, in \u001B[0;36mstack\u001B[0;34m(values, axis, name)\u001B[0m\n\u001B[1;32m   1463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1464\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1465\u001B[0m     \u001B[38;5;66;03m# If the input is a constant list, it can be converted to a constant op\u001B[39;00m\n\u001B[0;32m-> 1466\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1467\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mNotImplementedError\u001B[39;00m):\n\u001B[1;32m   1468\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Input list contains non-constant tensors\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001B[0m, in \u001B[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    181\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m Trace(trace_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrace_kwargs):\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1636\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m   1627\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1628\u001B[0m           _add_error_prefix(\n\u001B[1;32m   1629\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConversion function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconversion_func\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1632\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactual = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mbase_dtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1633\u001B[0m               name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1636\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mconversion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[1;32m   1639\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:343\u001B[0m, in \u001B[0;36m_constant_tensor_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_constant_tensor_conversion_function\u001B[39m(v, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    341\u001B[0m                                          as_ref\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    342\u001B[0m   _ \u001B[38;5;241m=\u001B[39m as_ref\n\u001B[0;32m--> 343\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconstant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001B[0m, in \u001B[0;36mconstant\u001B[0;34m(value, dtype, shape, name)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconstant\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconstant\u001B[39m(value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConst\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    172\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001B[39;00m\n\u001B[1;32m    173\u001B[0m \n\u001B[1;32m    174\u001B[0m \u001B[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_constant_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mallow_broadcast\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001B[0m, in \u001B[0;36m_constant_impl\u001B[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001B[0m\n\u001B[1;32m    277\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf.constant\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    278\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001B[0;32m--> 279\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_constant_eager_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverify_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m g \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mget_default_graph()\n\u001B[1;32m    282\u001B[0m tensor_value \u001B[38;5;241m=\u001B[39m attr_value_pb2\u001B[38;5;241m.\u001B[39mAttrValue()\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:304\u001B[0m, in \u001B[0;36m_constant_eager_impl\u001B[0;34m(ctx, value, dtype, shape, verify_shape)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_constant_eager_impl\u001B[39m(ctx, value, dtype, shape, verify_shape):\n\u001B[1;32m    303\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 304\u001B[0m   t \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_to_eager_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[1;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "min_epoch = 100\n",
    "max_epoch = 10000\n",
    "step_length = 500\n",
    "thred = 475\n",
    "running_rewards = collections.deque(maxlen=100)\n",
    "max_steps_per_epoch = 500\n",
    "all_rewards = []\n",
    "all_running_rewards = []\n",
    "t = tqdm.trange(max_epoch)\n",
    "for i in t:\n",
    "    start_state, _ = env.reset()\n",
    "    cur_step = 0\n",
    "    epoch_reward = 0\n",
    "    while cur_step < max_steps_per_epoch:\n",
    "        STEP_RES, loss= run_train_step(model, optimizer, start_state, step_length)\n",
    "        cur_step += step_length\n",
    "        values, actions, rewards, next_value, state, done = STEP_RES\n",
    "        epoch_reward += int(sum(rewards))\n",
    "        if done:\n",
    "            break\n",
    "    running_rewards.append(epoch_reward)\n",
    "    avg_reward = statistics.mean(running_rewards)\n",
    "    all_rewards.append(epoch_reward)\n",
    "    all_running_rewards.append(avg_reward)\n",
    "    t.set_postfix(running_rewards=avg_reward, current_reward=epoch_reward, loss=float(loss))\n",
    "    if avg_reward > thred and i > min_epoch:\n",
    "        break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a06a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:16.482010Z",
     "start_time": "2023-03-23T15:55:16.482002Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d141f82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:16.482687Z",
     "start_time": "2023-03-23T15:55:16.482679Z"
    }
   },
   "outputs": [],
   "source": [
    "_state, _ = env.reset()\n",
    "result = run_step(_state, model, 1000)\n",
    "values, actions, rewards, next_value, state, done = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b502d8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:16.483464Z",
     "start_time": "2023-03-23T15:55:16.483457Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(values)), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2eaf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:16.484250Z",
     "start_time": "2023-03-23T15:55:16.484243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Render an episode and save as a GIF file\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "\n",
    "render_env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "\n",
    "def render_episode(env: gym.Env, model: tf.keras.Model, max_steps: int): \n",
    "  state, info = env.reset()\n",
    "  state = tf.constant(state, dtype=tf.float32)\n",
    "  screen = env.render()\n",
    "  images = [Image.fromarray(screen)]\n",
    "  values = []\n",
    "\n",
    "  for i in range(1, max_steps + 1):\n",
    "    state = tf.expand_dims(state, 0)\n",
    "    value_output = model(state)\n",
    "    value_output = np.squeeze(value_output)\n",
    "    action = np.argmax(np.squeeze(value_output))\n",
    "    values.append(value_output[action])\n",
    "\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    state = tf.constant(state, dtype=tf.float32)\n",
    "\n",
    "    # Render screen every 10 steps\n",
    "    if i % 10 == 0:\n",
    "      screen = env.render()\n",
    "      images.append(Image.fromarray(screen))\n",
    "\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  return images, values\n",
    "\n",
    "\n",
    "# Save GIF image\n",
    "images,values = render_episode(render_env, model, max_steps_per_epoch)\n",
    "image_file = 'cartpole-v1.gif'\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(\n",
    "    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bf217",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:16.484854Z",
     "start_time": "2023-03-23T15:55:16.484846Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2972fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T15:55:16.485353Z",
     "start_time": "2023-03-23T15:55:16.485346Z"
    }
   },
   "outputs": [],
   "source": [
    "values = tf.stack(values)\n",
    "values = values.numpy()\n",
    "plt.plot(range(len(values)), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc62dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf211",
   "language": "python",
   "name": "tf211"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
