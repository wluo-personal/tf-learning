{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cf64ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.110223Z",
     "start_time": "2023-03-19T18:28:26.098263Z"
    }
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# disable tensorflow logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import tqdm\n",
    "import collections\n",
    "\n",
    "sys.path.insert(0, \"/home/wei/data/code/tf-learning/\")\n",
    "\n",
    "from lib.sumTree import SumTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad02aeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.113689Z",
     "start_time": "2023-03-19T18:28:27.111704Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO add current time step in to state for NN input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293f6b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.212541Z",
     "start_time": "2023-03-19T18:28:27.114856Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "initial_state, _ = env.reset()\n",
    "initial_state_shape = initial_state.shape\n",
    "action_space = env.action_space.n\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "gamma = 0.99\n",
    "lr = 0.005\n",
    "step_length = 50\n",
    "use_dueling = True\n",
    "batch_size = 64\n",
    "\n",
    "if use_dueling:\n",
    "    lr = 0.01\n",
    "    gamma = 0.99\n",
    "    \n",
    "replay_cache_size=5000\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a500b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-15T15:45:52.459819Z",
     "start_time": "2023-03-15T15:45:52.453876Z"
    }
   },
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1719071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.256834Z",
     "start_time": "2023-03-19T18:28:27.214304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            258         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None,)             0           ['dense_1[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.negative (TFOpLambda)  (None,)              0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " outs (Add)                     (None, 2)            0           ['dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'tf.math.negative[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,027\n",
      "Trainable params: 1,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The model will use basic Q-learning\n",
    "\"\"\"\n",
    "\n",
    "def get_model():\n",
    "    inputs = tf.keras.layers.Input(shape=initial_state_shape)\n",
    "    hidden = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "    hidden = tf.keras.layers.Dense(128, activation=\"relu\")(hidden)\n",
    "    outs = tf.keras.layers.Dense(action_space, activation=None)(hidden)\n",
    "    return tf.keras.Model(inputs, outs)\n",
    "\n",
    "def get_dueling_model():\n",
    "    \"\"\"\n",
    "    A = Q - S\n",
    "    Q = A + S - mean(A)\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=initial_state_shape)\n",
    "    hidden = tf.keras.layers.Dense(128, activation=\"relu\")(inputs)\n",
    "#     hidden = tf.keras.layers.Dense(128, activation=\"relu\")(hidden)\n",
    "    A = tf.keras.layers.Dense(action_space, activation=None)(hidden)\n",
    "    S = tf.keras.layers.Dense(1, activation=None)(hidden)\n",
    "    A_mean = tf.math.reduce_mean(A, axis=1, name=\"mean\")\n",
    "    outs = tf.keras.layers.Add(name=\"outs\")([A, S, -A_mean])\n",
    "    \n",
    "    return tf.keras.Model(inputs, outs)\n",
    "    \n",
    "if use_dueling:\n",
    "    model = get_dueling_model()\n",
    "else:\n",
    "    model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ed8c4",
   "metadata": {},
   "source": [
    "# define cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4a5a0bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.267567Z",
     "start_time": "2023-03-19T18:28:27.257961Z"
    }
   },
   "outputs": [],
   "source": [
    "replay_buffer = SumTree(replay_cache_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e08bc",
   "metadata": {},
   "source": [
    "# define run step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310b643",
   "metadata": {},
   "source": [
    "</br> 1. run for T steps or till the end of the game -- Get (1) (state_t, action_t, value, return_t_T, state_T ) # of (T-t) timestamp\n",
    "</br> 2. evaluate the loss for (state_t, action_t, return_t_T, state_T ), LOSS\n",
    "</br> 3. add the data to replay buffer\n",
    "</br> 4. random sample N from the replay buffer W.R.T the LOSS and compute gradient and update the model weights\n",
    "</br> 5. re-calculate the sampled data loss and update the replay buffer\n",
    "</br> 6. redo from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e946477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.274258Z",
     "start_time": "2023-03-19T18:28:27.268479Z"
    }
   },
   "outputs": [],
   "source": [
    "# everying should be tf instead of numpy\n",
    "def _run_step(start_state, model, step_length):\n",
    "    state = start_state\n",
    "    states = []\n",
    "    actions = []\n",
    "    values = []\n",
    "    returns = []\n",
    "    for t in range(step_length):\n",
    "        state = tf.expand_dims(state, 0)\n",
    "        value_output = model(state)\n",
    "        action = np.argmax(value_output.numpy().squeeze())\n",
    "        value = value_output[0, action]\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        values.append(value)\n",
    "        \n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        returns.append(reward)\n",
    "        if done:\n",
    "            break\n",
    "    next_state = state\n",
    "    next_value = model(tf.expand_dims(next_state, 0))\n",
    "    next_value = tf.reduce_max(tf.squeeze(next_value))\n",
    "    return states, actions, values, returns, next_state, next_value, done\n",
    "    \n",
    "def TD_organize(states, actions, values, returns, next_state, next_value, gamma=0.99):\n",
    "    \"\"\" organize the output of run_step into\n",
    "    (state_t, action_t, value_t, return_t to T, next_state, next_value, time step to next_state)\n",
    "    \"\"\"\n",
    "    values = tf.convert_to_tensor(values)\n",
    "    returns = tf.convert_to_tensor(returns)\n",
    "    \n",
    "    # 1. process returns\n",
    "    decays = tf.math.cumprod(returns * gamma, reverse=True) / gamma\n",
    "    dreturns = tf.math.cumsum(decays, reverse = True)\n",
    "    decays = decays * gamma\n",
    "    \n",
    "    data = []\n",
    "    next_state_tf = tf.expand_dims(next_state, 0)\n",
    "    \n",
    "    # 2. calculate loss\n",
    "    timestep = tf.ones_like(returns, dtype=tf.float32)\n",
    "    # or\n",
    "#     timestep = tf.math.cumsum(returns, reverse = True)\n",
    "    diff = calculate_diff(values, next_value, dreturns, decays, timestep)\n",
    "    \n",
    "    \n",
    "    # 3.\n",
    "    for t in range(len(states)-1,-1,-1):\n",
    "        record = (states[t], actions[t], values[t], dreturns[t], decays[t], next_state_tf, next_value, timestep[t])\n",
    "        data.append(record)\n",
    "    return data, diff\n",
    "        \n",
    "    \n",
    "def calculate_diff(value_t, value_T, accumulated_returns, decay, timestep=1.0):\n",
    "    target = decay * value_T + accumulated_returns\n",
    "    value_t = value_t / timestep\n",
    "    target = target / timestep\n",
    "    diff = (target - value_t) ** 2 # array\n",
    "    return diff\n",
    "\n",
    "def run_step(start_state, model, step_length, gamma=0.99):\n",
    "    states, actions, values, returns, next_state, next_value, done = _run_step(start_state, model, step_length)\n",
    "    \n",
    "    \n",
    "    data, diff = TD_organize(states, actions, values, returns, next_state, next_value, gamma)\n",
    "    for data_record, diff_record in zip(data, diff):\n",
    "        replay_buffer.add_new_data(data_record, diff_record)\n",
    "    return next_state, done, len(returns)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d67e",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbdca17",
   "metadata": {},
   "source": [
    "### run step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2202ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.298835Z",
     "start_time": "2023-03-19T18:28:27.275106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/anaconda3/envs/tf_211/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "state_, _ = env.reset()\n",
    "states, actions, values, returns, next_state, next_value, done = _run_step(state_, model, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee9883",
   "metadata": {},
   "source": [
    "### organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9abc6985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.310566Z",
     "start_time": "2023-03-19T18:28:27.299851Z"
    }
   },
   "outputs": [],
   "source": [
    "data, diff = TD_organize(states, actions, values, returns, next_state, next_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca574d",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ab170",
   "metadata": {},
   "source": [
    "### all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45def474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.335223Z",
     "start_time": "2023-03-19T18:28:27.311513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.12146739,  1.5232143 , -0.22919363, -2.6031637 ], dtype=float32),\n",
       " True,\n",
       " 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_, _ = env.reset()\n",
    "run_step(state_, model, 100, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e2ad68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.339105Z",
     "start_time": "2023-03-19T18:28:27.336974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=197.263>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.tree_.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa6bd7",
   "metadata": {},
   "source": [
    "# Update Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9dba29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.345803Z",
     "start_time": "2023-03-19T18:28:27.340193Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample(batch_size):\n",
    "    tree_instances = replay_buffer.sample(batch_size)\n",
    "    states = []\n",
    "    next_states = []\n",
    "    losses = []\n",
    "    for ins in tree_instances:\n",
    "        state, a, v, r, decay, next_state_tf, next_value, tstep = ins.data\n",
    "        losses.append(ins.weight)\n",
    "        states.append(state)\n",
    "        next_states.append(next_state_tf)\n",
    "    return tree_instances, states, next_states, losses\n",
    "        \n",
    "def update_model(state, model, optimizer, batch_size=64, step_length=100, gamma=0.99):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        next_state, done, returns_sum = run_step(state_, model, step_length, gamma)\n",
    "        tree_instances, states, next_states, losses = sample(batch_size)\n",
    "        loss_value = tf.math.reduce_mean(losses)\n",
    "    try:\n",
    "        gradient = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "    except Exception:\n",
    "        return tree_instances, tree_instances, tree_instances, True\n",
    "    update_loss(tree_instances, model)\n",
    "    return next_state, done, returns_sum, False\n",
    "    \n",
    "def update_loss(tree_instances, model):\n",
    "    states = []\n",
    "    next_states = []\n",
    "    accumulated_returns = []\n",
    "    decays = []\n",
    "    timesteps = []\n",
    "    \n",
    "    for ins in tree_instances:\n",
    "        states.append(ins.data[0])\n",
    "        next_states.append(ins.data[5])\n",
    "        accumulated_returns.append(ins.data[3])\n",
    "        decays.append(ins.data[4])\n",
    "        timesteps.append(ins.data[-1])\n",
    "    states = tf.concat(states, axis=0)\n",
    "    next_states = tf.concat(next_states, axis=0)\n",
    "    value_t = model(states)\n",
    "    value_T = model(next_states)\n",
    "    value_t = tf.math.reduce_max(value_t, axis=1)\n",
    "    value_T = tf.math.reduce_max(value_T, axis=1)\n",
    "    accumulated_returns = tf.stack(accumulated_returns, axis=0)\n",
    "    decays = tf.stack(decays, axis=0)\n",
    "    timesteps = tf.stack(timesteps, axis=0)\n",
    "    diff = calculate_diff(value_t, value_T, accumulated_returns, decays, timestep=timesteps)\n",
    "    for idx, ins in enumerate(tree_instances):\n",
    "        old_data = ins.data\n",
    "        s, a, v, d, dc, ns, nv, t = old_data\n",
    "        new_data = (s,a, value_t[idx], d, dc, ns, value_T[idx], t)\n",
    "        new_diff = diff[idx]\n",
    "        replay_buffer.update_node_by_instance(ins, new_data, new_diff)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1e7644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:27.505308Z",
     "start_time": "2023-03-19T18:28:27.346642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights before update: 197.26300048828125\n",
      "weights after update: 248.95452880859375\n"
     ]
    }
   ],
   "source": [
    "state_, _ = env.reset()\n",
    "print(f\"weights before update: {replay_buffer.tree_.weight}\")\n",
    "next_state, done, returns_sum, flag_exception = update_model(state_, model, optimizer, 64)\n",
    "print(f\"weights after update: {replay_buffer.tree_.weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6669b5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47924df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:28:29.301080Z",
     "start_time": "2023-03-19T18:28:27.506599Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/10000 [00:01<22:27,  7.41it/s, episode_reward=10, running_reward=14.8]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "!!!!!!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m     state, done, returns_sum, flag_excption \u001B[38;5;241m=\u001B[39m update_model(state, model, optimizer, batch_size, step_length, gamma)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flag_excption:\n\u001B[0;32m---> 16\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m!!!!!!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     17\u001B[0m     episode_rewards \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m returns_sum\n\u001B[1;32m     18\u001B[0m running_reward \u001B[38;5;241m=\u001B[39m running_reward \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.99\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.1\u001B[39m \u001B[38;5;241m*\u001B[39m episode_rewards\n",
      "\u001B[0;31mValueError\u001B[0m: !!!!!!"
     ]
    }
   ],
   "source": [
    "min_episode = 100\n",
    "max_episode = 10000\n",
    "max_steps_per_episode = 700\n",
    "threds = 475\n",
    "running_reward = 0.0\n",
    "step_length = 200\n",
    "t = tqdm.trange(max_episode)\n",
    "# replay_buffer.build()\n",
    "for i in t:\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    episode_rewards = 0.0\n",
    "    while not done:\n",
    "        state, done, returns_sum, flag_excption = update_model(state, model, optimizer, batch_size, step_length, gamma)\n",
    "        if flag_excption:\n",
    "            raise ValueError('!!!!!!')\n",
    "        episode_rewards += returns_sum\n",
    "    running_reward = running_reward * 0.99 + 0.1 * episode_rewards\n",
    "    t.set_postfix(running_reward=running_reward, episode_reward=episode_rewards)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55927275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:29:00.579386Z",
     "start_time": "2023-03-19T18:29:00.576163Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "for ins in state:\n",
    "    losses.append(ins.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "064b58b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T18:29:04.210531Z",
     "start_time": "2023-03-19T18:29:04.204889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=3.4855995>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=88.39711>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=285.92062>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=342.65555>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=299.86472>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=80.85233>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=107.11661>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=245.54613>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=17.49826>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=151.62375>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=234.35164>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=114.31948>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=105.245155>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=107.902985>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=22.069914>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=165.12369>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=157.15266>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=251.80078>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=51.741478>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=211.50021>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=112.60407>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=189.9929>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=114.31948>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=342.65555>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=245.54613>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=245.54613>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=115.74881>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=211.50021>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=13.314327>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=211.50021>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=342.65555>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=106.428116>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=126.67558>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=116.34718>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=342.65555>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=146.4489>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=342.65555>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=80.29789>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=106.428116>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=13.231835>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=211.50021>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=189.9929>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=47.05733>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=154.07127>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=185.67094>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=105.245155>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=59.33435>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=118.024475>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=105.245155>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=106.428116>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=342.65555>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=74.26177>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=234.35164>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=189.9929>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=81.815445>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=155.84502>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=17.038233>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=342.65555>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=23.99612>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=118.024475>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=211.50021>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=234.35164>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=251.80078>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=185.67094>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9415391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf211",
   "language": "python",
   "name": "tf211"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
