{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0925552e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.437744Z",
     "start_time": "2023-03-08T16:48:14.417799Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 16:48:14.524514: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 16:48:14.605676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:14.605692: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-08 16:48:14.987591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:14.987628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:14.987632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import tqdm\n",
    "import collections, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae49ae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.444054Z",
     "start_time": "2023-03-08T16:48:15.439428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "n_hidden_unit = 128\n",
    "n_action_space = env.action_space.n\n",
    "initial_state, _ = env.reset()\n",
    "initial_state_shape = initial_state.shape\n",
    "gamma = 0.99\n",
    "print(f\"initial state shape: {initial_state_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e059304",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92943b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.580643Z",
     "start_time": "2023-03-08T16:48:15.445253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " common (Dense)                 (None, 128)          640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " output_action_logits (Dense)   (None, 2)            258         ['common[0][0]']                 \n",
      "                                                                                                  \n",
      " output_value (Dense)           (None, 1)            129         ['common[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,027\n",
      "Trainable params: 1,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 16:48:15.533511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 16:48:15.533677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533835: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-08 16:48:15.533864: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-08 16:48:15.534030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    The input will be the state\n",
    "    The output will be \n",
    "    (1) action logits, shape 2\n",
    "    (2) value, shape 1\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=initial_state_shape)\n",
    "    comm = tf.keras.layers.Dense(n_hidden_unit, activation=\"relu\", name=\"common\")(inputs)\n",
    "    action_logits = tf.keras.layers.Dense(n_action_space, activation=None, name=\"output_action_logits\")(comm)\n",
    "    value = tf.keras.layers.Dense(1, activation=None, name=\"output_value\")(comm)\n",
    "    return tf.keras.Model(inputs, [action_logits, value])\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17c7ec",
   "metadata": {},
   "source": [
    "# Design training data collection -- very important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f75ddf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.587296Z",
     "start_time": "2023-03-08T16:48:15.582601Z"
    }
   },
   "outputs": [],
   "source": [
    "def env_step(action: int):\n",
    "    \"\"\"\n",
    "    env.step cannot be call inside tf graph, so we need to convert it to tf function.\n",
    "    \"\"\"\n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    return (\n",
    "        state.astype(np.float32), \n",
    "        np.array(reward,dtype=np.float32),\n",
    "        np.array(done, dtype=np.int32)\n",
    "    )\n",
    "\n",
    "def tf_env_step(action):\n",
    "    return tf.numpy_function(env_step, [action], [tf.float32, tf.float32, tf.int32])\n",
    "\n",
    "def run_epoch(initial_state, max_steps, model):\n",
    "    \"\"\"\n",
    "    return action probs, estimated values, actual rewards\n",
    "    \"\"\"\n",
    "    action_probs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    estimated_values = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    rewards = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    state = initial_state\n",
    "    # tf.range make sure this can be called in a tf graph\n",
    "    for t in tf.range(max_steps):\n",
    "        state = tf.expand_dims(state, 0) # add batch dimension\n",
    "        action_logit, estimated_value = model(state)\n",
    "        # sample the action\n",
    "        action = tf.random.categorical(action_logit, num_samples=1, dtype=None, seed=None, name=None)[0,0]\n",
    "        action_prob = tf.keras.activations.softmax(action_logit) # the first zero is the batch dim\n",
    "        \n",
    "        state, reward, done = tf_env_step(action)\n",
    "        state.set_shape(initial_state_shape)\n",
    "        \n",
    "        action_probs = action_probs.write(t, tf.squeeze(action_prob)[action])\n",
    "        estimated_values = estimated_values.write(t, tf.squeeze(estimated_value))\n",
    "        rewards = rewards.write(t, tf.squeeze(reward))\n",
    "        \n",
    "        if tf.cast(done, tf.bool):\n",
    "            break\n",
    "    action_probs = action_probs.stack()\n",
    "    estimated_values = estimated_values.stack()\n",
    "    rewards = rewards.stack()\n",
    "    return action_probs, estimated_values, rewards\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b925b",
   "metadata": {},
   "source": [
    "## test the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3285b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.634799Z",
     "start_time": "2023-03-08T16:48:15.588633Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/anaconda3/envs/tf_211/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(19,), dtype=float32, numpy=\n",
       " array([0.50248265, 0.5073823 , 0.4868419 , 0.49275556, 0.49724457,\n",
       "        0.50416005, 0.50329655, 0.5075689 , 0.48648456, 0.5077627 ,\n",
       "        0.5138136 , 0.5199265 , 0.47382995, 0.47918737, 0.51597106,\n",
       "        0.47807068, 0.51872367, 0.47588745, 0.47764164], dtype=float32)>,\n",
       " <tf.Tensor: shape=(19,), dtype=float32, numpy=\n",
       " array([-1.69189821e-04,  5.43815307e-02,  1.12011455e-01,  5.13284579e-02,\n",
       "        -1.31513423e-03, -5.45527041e-03, -3.94668197e-04,  5.23516908e-02,\n",
       "         1.10388279e-01,  5.11532128e-02,  1.08461022e-01,  1.66180730e-01,\n",
       "         2.24010125e-01,  1.62061080e-01,  1.03708997e-01,  1.61501169e-01,\n",
       "         1.04573116e-01,  1.63015470e-01,  1.07496031e-01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(19,), dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state, _ = env.reset()\n",
    "A = run_epoch(initial_state, 500, model)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1686003",
   "metadata": {},
   "source": [
    "# Calculate returns from rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39520c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.639587Z",
     "start_time": "2023-03-08T16:48:15.636041Z"
    }
   },
   "outputs": [],
   "source": [
    "# this will be called inside a tf function\n",
    "def calculate_returns(rewards, normalize=tf.constant(True)):\n",
    "    returns = tf.TensorArray(np.float32, size=0, dynamic_size=True)\n",
    "    discounted_sum = tf.constant(0.0)\n",
    "    discounted_sum_shape = discounted_sum.shape\n",
    "    # cannot use rewards.shape since it will cause None issue. The tf.shape will handle this problem\n",
    "    for t in tf.range(tf.shape(rewards)[0]-1, -1, -1):\n",
    "        discounted_sum = discounted_sum * gamma + rewards[t]\n",
    "        discounted_sum.set_shape(discounted_sum_shape)\n",
    "        returns = returns.write(t, discounted_sum)\n",
    "    returns = returns.stack()\n",
    "    \n",
    "    if normalize:\n",
    "        returns = (returns - tf.math.reduce_mean(returns)) / (tf.math.reduce_std(returns) + eps)\n",
    "    return returns\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b39ae",
   "metadata": {},
   "source": [
    "## test the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3b3e2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.657243Z",
     "start_time": "2023-03-08T16:48:15.640711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw returns: [ 1.5966538   1.4292301   1.2601154   1.0892925   0.916744    0.7424526\n",
      "  0.56640065  0.3885705   0.20894408  0.02750331 -0.15577021 -0.34089494\n",
      " -0.5278897  -0.71677333 -0.90756494 -1.1002836  -1.294949   -1.4915807\n",
      " -1.6901985 ]\n",
      "mean: 1.0038677089596604e-07\n",
      "std: 0.9999999403953552\n"
     ]
    }
   ],
   "source": [
    "r = calculate_returns(A[-1])\n",
    "print(f\"raw returns: {r}\")\n",
    "print(f\"mean: {tf.math.reduce_mean(r)}\")\n",
    "print(f\"std: {tf.math.reduce_std(r)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1ec63",
   "metadata": {},
   "source": [
    "# Calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b88523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.661607Z",
     "start_time": "2023-03-08T16:48:15.658715Z"
    }
   },
   "outputs": [],
   "source": [
    "# The loss will be called inside tf function\n",
    "huber = tf.losses.Huber(reduction=tf.losses.Reduction.SUM) # the SUM_OVER_BATCH will normalize by batch size\n",
    "def compute_loss(action_probs, estimated_values, actual_values):\n",
    "#     expand dim - this is extremly important. Without below, the loss is wrong and the model will not learn anything\n",
    "    action_probs, estimated_values, actual_values = [\n",
    "        tf.cond(tf.cast(x.shape.ndims==1, tf.bool), \n",
    "                lambda: tf.expand_dims(x,1), \n",
    "                lambda: x\n",
    "               )  for x in (action_probs, estimated_values, actual_values)]\n",
    "    \n",
    "    \n",
    "    advantage = actual_values - estimated_values\n",
    "#     advantage = actual_values\n",
    "    log_action = tf.math.log(tf.clip_by_value(action_probs, eps, 1e10))\n",
    "    loss_actor = - tf.math.reduce_sum(advantage * log_action)\n",
    "    loss_huber = huber(estimated_values, actual_values)\n",
    "    loss = loss_actor + loss_huber\n",
    "    \n",
    "    return loss, loss_actor, loss_huber\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb14728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T15:03:39.911371Z",
     "start_time": "2023-03-08T15:03:39.894632Z"
    }
   },
   "source": [
    "## test the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4444df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.678869Z",
     "start_time": "2023-03-08T16:48:15.662662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=8.165183>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-1.3731375>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.538321>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = compute_loss(A[0], A[1], calculate_returns(A[-1]))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7625068",
   "metadata": {},
   "source": [
    "# Define train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812c7c1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:15.685268Z",
     "start_time": "2023-03-08T16:48:15.680658Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "@tf.function\n",
    "def train_step(initial_state, max_steps, model, optimizer):\n",
    "    \"\"\"\n",
    "    1. run epoch to collect data\n",
    "    2. calculate loss\n",
    "    3. update weights\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. run epoch to collect data\n",
    "        action_probs, estimated_values, rewards = run_epoch(initial_state, max_steps, model)\n",
    "        actual_values = calculate_returns(rewards)\n",
    "        \n",
    "        # 2. calculate loss\n",
    "        loss, loss_actor, loss_huber = compute_loss(action_probs, estimated_values, actual_values)\n",
    "        \n",
    "        \n",
    "    # calculate gradient\n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "    total_rewards = tf.math.reduce_sum(tf.squeeze(rewards))\n",
    "    A = (loss, loss_actor, loss_huber)\n",
    "    return total_rewards, A\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d22a1",
   "metadata": {},
   "source": [
    "## test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a0b073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:17.266628Z",
     "start_time": "2023-03-08T16:48:15.686287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wei/anaconda3/envs/tf_211/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=40.0>,\n",
       " (<tf.Tensor: shape=(), dtype=float32, numpy=19.939402>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=-2.9859664>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=22.925367>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state, _ = env.reset()\n",
    "train_step(initial_state, 500, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fedf77",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e788eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:45.748340Z",
     "start_time": "2023-03-08T16:48:17.267912Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 437/10000 [00:28<10:23, 15.35it/s, avg_rewards=477, current_rewards=500] \n"
     ]
    }
   ],
   "source": [
    "min_epochs_to_run = 100\n",
    "max_epochs_to_run = 10000\n",
    "max_steps_per_epoch = 500\n",
    "reward_thred = 475\n",
    "t = tqdm.trange(max_epochs_to_run)\n",
    "q = collections.deque(maxlen=100)\n",
    "rewards_history = []\n",
    "for i in t:\n",
    "    initial_state, _ = env.reset()\n",
    "    initial_state = tf.constant(initial_state, dtype=tf.float32)\n",
    "    epoch_reward, loss = train_step(initial_state, max_steps_per_epoch, model, optimizer)\n",
    "    epoch_reward = int(epoch_reward)\n",
    "    rewards_history.append(epoch_reward)\n",
    "    q.append(epoch_reward)\n",
    "    avg_rewards = statistics.mean(q)\n",
    "    t.set_postfix(current_rewards=epoch_reward, avg_rewards=avg_rewards)\n",
    "    \n",
    "    if avg_rewards > reward_thred and i > min_epochs_to_run:\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4edec746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T16:48:45.753375Z",
     "start_time": "2023-03-08T16:48:45.750025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6d200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf211",
   "language": "python",
   "name": "tf211"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
